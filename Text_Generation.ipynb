{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pickle\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(text_df.text.values)\n",
    "joined_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text = joined_text[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_tokens_index = {token: idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words =  10 \n",
    "input_words = []\n",
    "next_words = []\n",
    "\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i + n_words])\n",
    "    next_words.append (tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
    "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words):\n",
    "    for j, word in enumerate(words):\n",
    "        X[i, j, unique_tokens_index[word]] = 1\n",
    "\n",
    "    y[i, unique_tokens_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "135/135 [==============================] - 31s 195ms/step - loss: 6.8742 - accuracy: 0.0546\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 40s 296ms/step - loss: 6.6463 - accuracy: 0.0626\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 41s 307ms/step - loss: 6.5151 - accuracy: 0.0676\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 41s 303ms/step - loss: 6.3396 - accuracy: 0.0763\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 41s 303ms/step - loss: 6.1262 - accuracy: 0.0885\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 41s 303ms/step - loss: 5.8868 - accuracy: 0.1015\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 41s 301ms/step - loss: 5.6327 - accuracy: 0.1182\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 40s 296ms/step - loss: 5.3523 - accuracy: 0.1410\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 40s 297ms/step - loss: 5.0623 - accuracy: 0.1631\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 40s 297ms/step - loss: 4.7568 - accuracy: 0.1905\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 773s 6s/step - loss: 4.4424 - accuracy: 0.2294\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 27s 201ms/step - loss: 4.1288 - accuracy: 0.2589\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 24s 175ms/step - loss: 3.8124 - accuracy: 0.3044\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 27s 201ms/step - loss: 3.4991 - accuracy: 0.3449\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 42s 308ms/step - loss: 3.1945 - accuracy: 0.3955\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 41s 307ms/step - loss: 2.9039 - accuracy: 0.4423\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 42s 314ms/step - loss: 2.6328 - accuracy: 0.4871\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 41s 307ms/step - loss: 2.3738 - accuracy: 0.5379\n",
      "Epoch 19/30\n",
      "135/135 [==============================] - 43s 318ms/step - loss: 2.1299 - accuracy: 0.5882\n",
      "Epoch 20/30\n",
      "135/135 [==============================] - 22s 165ms/step - loss: 1.9004 - accuracy: 0.6405\n",
      "Epoch 21/30\n",
      "135/135 [==============================] - 24s 176ms/step - loss: 1.6968 - accuracy: 0.6894\n",
      "Epoch 22/30\n",
      "135/135 [==============================] - 24s 180ms/step - loss: 1.5036 - accuracy: 0.7366\n",
      "Epoch 23/30\n",
      "135/135 [==============================] - 24s 174ms/step - loss: 1.3257 - accuracy: 0.7794\n",
      "Epoch 24/30\n",
      "135/135 [==============================] - 23s 173ms/step - loss: 1.1749 - accuracy: 0.8138\n",
      "Epoch 25/30\n",
      "135/135 [==============================] - 23s 174ms/step - loss: 1.0214 - accuracy: 0.8533\n",
      "Epoch 26/30\n",
      "135/135 [==============================] - 25s 183ms/step - loss: 0.8794 - accuracy: 0.8858\n",
      "Epoch 27/30\n",
      "135/135 [==============================] - 24s 181ms/step - loss: 0.7695 - accuracy: 0.9010\n",
      "Epoch 28/30\n",
      "135/135 [==============================] - 24s 180ms/step - loss: 0.6597 - accuracy: 0.9228\n",
      "Epoch 29/30\n",
      "135/135 [==============================] - 23s 171ms/step - loss: 0.5680 - accuracy: 0.9373\n",
      "Epoch 30/30\n",
      "135/135 [==============================] - 23s 170ms/step - loss: 0.4773 - accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27885103fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
    "model.fit(X, y, batch_size=128, epochs=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "    input_text = input_text.lower()\n",
    "    X = np.zeros((1,n_words,len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        X[0, i, unique_tokens_index[word]] = 1\n",
    "    \n",
    "    predictions = model.predict(X)[0]\n",
    "    return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word('He will have to look into this thing and he', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chairman', 'who', 'on', 'however', 'classroom']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, text_length, creativity = 3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(text_length):\n",
    "        sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+n_words])\n",
    "        try:\n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice = random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current += 1\n",
    "    return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Presidient of united states has announced that from legislatures in for for of but we we we white they obama it the is it one has out one a hasn a hillary the the to was we nearly women in in i in i i baylee into i i my into in as found in in in'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"The Presidient of united states has announced that  \", 50, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
